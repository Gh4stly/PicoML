{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(v,w):\n",
    "    \"\"\"Adds corresponding elements\"\"\"\n",
    "    assert len(v) == len(w), \"vectors must be the same length\"\n",
    "\n",
    "    return [v_i + w_i for v_i, w_i in zip(v, w)]\n",
    "\n",
    "\n",
    "def subtract(v, w):\n",
    "    \"\"\"Subtracts corresponding elements\"\"\"\n",
    "    assert len(v) == len(w), \"vectors must be the same length\"\n",
    "\n",
    "    return [v_i - w_i for v_i, w_i in zip(v, w)]\n",
    "\n",
    "def vector_sum(vectors):\n",
    "    \"\"\"Sums all corresponding elements\"\"\"\n",
    "    # Check that vectors is not empty\n",
    "    assert vectors, \"no vectors provided!\"\n",
    "\n",
    "    # Check the vectors are all the same size\n",
    "    num_elements = len(vectors[0])\n",
    "    assert all(len(v) == num_elements for v in vectors), \"different sizes!\"\n",
    "\n",
    "    # the i-th element of the result is the sum of every vector[i]\n",
    "    return [sum(vector[i] for vector in vectors)\n",
    "            for i in range(num_elements)]\n",
    "\n",
    "def scalar_multiply(c,v):\n",
    "    \"\"\"Multiplies every element by c\"\"\"\n",
    "    return [c * v_i for v_i in v]\n",
    "\n",
    "def vector_mean(vectors):\n",
    "    \"\"\"Computes the element-wise average\"\"\"\n",
    "    n = len(vectors)\n",
    "    return scalar_multiply(1/n, vector_sum(vectors))\n",
    "\n",
    "def dot(v, w):\n",
    "    \"\"\"Computes v_1 * w_1 + ... + v_n * w_n\"\"\"\n",
    "    assert len(v) == len(w), \"vectors must be same length\"\n",
    "    #print(v)\n",
    "    #print(w)\n",
    "    return sum(v_i * w_i for v_i, w_i in zip(v, w))\n",
    "def partial_difference_quotient(f,v,i,h):\n",
    "        \"\"\"Returns the i-th partial difference quotient of f at v\"\"\"\n",
    "        w = [v_j + (h if j == i else 0)    # add h to just the ith element of v\n",
    "             for j, v_j in enumerate(v)]\n",
    "    \n",
    "        return (f(w) - f(v)) / h\n",
    "    \n",
    "def estimate_gradient(f,v,h = 0.0001):\n",
    "    return [partial_difference_quotient(f, v, i, h)\n",
    "            for i in range(len(v))]\n",
    "\n",
    "def gradient_step(v, gradient, step_size):\n",
    "    step = scalar_multiply(step_size, gradient)\n",
    "    return add(v, step)\n",
    "\n",
    "def sigmoid(t):\n",
    "    return 1 / (1 + math.exp(-t))\n",
    "\n",
    "def neuron_output(weights, inputs):\n",
    "    # weights includes the bias term, inputs includes a 1\n",
    "    #print(inputs)\n",
    "    #print(weights)\n",
    "    return sigmoid(dot(weights, inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_layers(size,num_layers):\n",
    "    \"\"\"\n",
    "    Create an array of random weights\n",
    "    size = number of weights in each layer\n",
    "    \"\"\"\n",
    "    network = []\n",
    "    for i in range(num_layers):\n",
    "        network.append([random.random() for _ in range(size + 1)])\n",
    "    return network   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sqerror_gradients(network,\n",
    "                      input_vector,\n",
    "                      target_vector):\n",
    "    \"\"\"\n",
    "    Given a neural network, an input vector, and a target vector,\n",
    "    make a prediction and compute the gradient of the squared error\n",
    "    loss with respect to the neuron weights.\n",
    "    \"\"\"\n",
    "    # forward pass\n",
    "    hidden_outputs, outputs = feed_forward(network, input_vector)\n",
    "\n",
    "    # gradients with respect to output neuron pre-activation outputs\n",
    "    output_deltas = [output * (1 - output) * (output - target)\n",
    "                     for output, target in zip(outputs, target_vector)]\n",
    "\n",
    "    # gradients with respect to output neuron weights\n",
    "    output_grads = [[output_deltas[i] * hidden_output\n",
    "                     for hidden_output in hidden_outputs + [1]]\n",
    "                    for i, output_neuron in enumerate(network[-1])]\n",
    "\n",
    "    # gradients with respect to hidden neuron pre-activation outputs\n",
    "    hidden_deltas = [hidden_output * (1 - hidden_output) *\n",
    "                         dot(output_deltas, [n[i] for n in network[-1]])\n",
    "                     for i, hidden_output in enumerate(hidden_outputs)]\n",
    "\n",
    "    # gradients with respect to hidden neuron weights\n",
    "    hidden_grads = [[hidden_deltas[i] * input for input in input_vector + [1]]\n",
    "                    for i, hidden_neuron in enumerate(network[0])]\n",
    "\n",
    "    return [hidden_grads, output_grads]\n",
    "\n",
    "def training_network(xs,ys,network,learning_rate = 1.0):    \n",
    "    for epoch in range(20000):\n",
    "            for x, y in zip(xs, ys):\n",
    "                gradients = sqerror_gradients(network, x, y)\n",
    "    \n",
    "            # Take a gradient step for each neuron in each layer\n",
    "                network = [[gradient_step(neuron, grad, -learning_rate)\n",
    "                            for neuron, grad in zip(layer, layer_grad)]\n",
    "                           for layer, layer_grad in zip(network, gradients)]\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data,percent):\n",
    "    \"\"\"\n",
    "    Split data based on percentage for testing/training networks\n",
    "    \"\"\"\n",
    "    training = data[:int(len(data) * percent)]\n",
    "    test = data[-int(len(data) * (1 - percent)):]\n",
    "    return training,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feed_forward(neural_network,\n",
    "                 input_vector):\n",
    "    \"\"\"\n",
    "    Feeds the input vector through the neural network.\n",
    "    Returns the outputs of all layers (not just the last one).\n",
    "    \"\"\"\n",
    "    outputs = []\n",
    "\n",
    "    for layer in neural_network:\n",
    "        input_with_bias = input_vector + [1]              # Add a constant.\n",
    "        output = [neuron_output(neuron, input_with_bias)  # Compute the output\n",
    "                  for neuron in layer]                    # for each neuron.\n",
    "        outputs.append(output)                            # Add to results.\n",
    "\n",
    "        # Then the input to the next layer is the output of this one\n",
    "        input_vector = output\n",
    "\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run test to make sure neural net is operating properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_neuralnet():\n",
    "    \"\"\"\n",
    "    A quick test to make sure we can train the NN\n",
    "    We're training it on learning XOR since its fast, simple,\n",
    "    and if something goes wrong we can troubleshoot easy\n",
    "    \"\"\"\n",
    "    full_network = []\n",
    "    hidden_layer = create_layers(2,2)\n",
    "    output_layer = create_layers(2,1)\n",
    "    full_network.append(hidden_layer)\n",
    "    full_network.append(output_layer)\n",
    "    #test data\n",
    "    xs = [[0., 0], [0., 1], [1., 0], [1., 1]]\n",
    "    ys = [[0.], [1.], [1.], [0.]]\n",
    "    network = training_network(xs,ys,full_network)\n",
    "    #lets make sure everything is working\n",
    "    print(\"Running assert block\")\n",
    "    assert feed_forward(network, [0, 0])[-1][0] < 0.01\n",
    "    assert feed_forward(network, [0, 1])[-1][0] > 0.99\n",
    "    assert feed_forward(network, [1, 0])[-1][0] > 0.99\n",
    "    assert feed_forward(network, [1, 1])[-1][0] < 0.01\n",
    "    print(\"Test complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_neuralnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "network = training_network(xs,ys,full_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "feed_forward(network,[0,1])[-1][0]\n",
    "print(feed_forward(network,[1,0])[-1][0])\n",
    "print(feed_forward(network,[1,1])[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"small.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = df.sample(frac = 0.6)\n",
    "test_set = df.drop(training_set.index)\n",
    "test_set = test_set.reset_index()\n",
    "training_set = training_set.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs = []\n",
    "Ys = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = training_set.columns.tolist()\n",
    "print(columns[1:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = training_set.columns.tolist()\n",
    "for i in range(len(training_set)):\n",
    "    Xs.append(training_set.loc[i, columns[1:-1]].values.flatten().tolist())\n",
    "for i in range(len(training_set)):\n",
    "    Ys.append(training_set.loc[i,columns[-1]].flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(Xs))\n",
    "print(len(Ys))\n",
    "print(len(training_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_network = []\n",
    "hidden_layer = create_layers(7,7)\n",
    "output_layer = create_layers(7,1)\n",
    "full_network.append(hidden_layer)\n",
    "full_network.append(output_layer)\n",
    "print(len(full_network[1]))\n",
    "print(len(Xs))\n",
    "print(len(Ys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = training_network(Xs,Ys,full_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "test_y = []\n",
    "columns = test_set.columns.tolist()\n",
    "for i in range(len(test_set)):\n",
    "    test_x.append(test_set.loc[i, columns[1:-1]].values.flatten().tolist())\n",
    "for i in range(len(test_set)):\n",
    "    test_y.append(test_set.loc[i,columns[-1]].flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = 0\n",
    "actual_positive = 0\n",
    "for item in test_x:\n",
    "    if feed_forward(network,item)[-1][0] > 0.01:\n",
    "        positive += 1\n",
    "for item in test_y:\n",
    "    if 1 in item:\n",
    "        actual_positive += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calc positive: \" + str(positive))\n",
    "print(\"Actual positive: \" + str(actual_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x = []\n",
    "final_y = []\n",
    "columns = df2.columns.tolist()\n",
    "for i in range(len(df2)):\n",
    "    final_x.append(df2.loc[i, columns[:-1]].values.flatten().tolist())\n",
    "for i in range(len(df2)):\n",
    "    final_y.append(df2.loc[i,columns[-1]].flatten().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = 0\n",
    "actual_positive = 0\n",
    "for item in final_x:\n",
    "    if feed_forward(network,item)[-1][0] > 0.01:\n",
    "        positive += 1\n",
    "for item in final_y:\n",
    "    if 1 in item:\n",
    "        actual_positive += 1\n",
    "print(\"Calc positive: \" + str(positive))\n",
    "print(\"Actual positive: \" + str(actual_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [1,2,3,4,5,6,7,8,9,0]\n",
    "training = data[: int(len(data)*0.6)]\n",
    "test = data[-int(len(data)*0.4):]\n",
    "print(training)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
